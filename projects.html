<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8">
    <title>Casey Salvador | Developer</title>

    <link rel="stylesheet" href="css/normalize.css">
   <link href='http://fonts.googleapis.com/css?family=Roboto:400,100,700' rel='stylesheet' type='text/css'>
    <link rel="stylesheet" type="text/css" href="css/main.css">
    <link rel="stylesheet" type="text/css" href="css/responsive.css">

    <meta name="viewport" content="width=device-width, initial-scale=1.0">

  </head>
  <body>
    <header id="project">
      <a href="index.html" id="logo">
        <h1>2015 Wells Fargo Data Competition</h1>
        <h2>Data Science 101</h2>
      </a>
      <nav id="navigation">
        <ul>
          <li><a href="index.html">Home</a></li>
          <li><a href="contact.html">Contact</a></li>
          <li><a href="projects.html" class="selected">Projects</a></li>
        </ul>
      </nav>
    </header>

    <div id="wrapper">

      <section id="primary">

        <h1 class="projecth1">A Plan for Action for Social Media Response</h1><br>

        <h4 class="projecth4"> ~ About</h4>

        <p>Welcome! I'm Casey Salvador, undergraduate of the College of Charleston. This portion is dedicated to provide information about the Wells Fargo Analytics competition for DATA 101. Enjoy and feel free to navigate the following sections, which provides information on the project. Please feel free as well to contact me via my contacts page.</p>

        <h4 class="projecth4"> ~ Challenge</h4>

        <p>Dialogues on social media can provide tremendous insight into the behaviors, desires, pains, and thoughts of consumers. We'd like your help in developing a repeatable process that identifies, classifies, and extracts the underlying drivers of consumer financial conversations and comments in social media data.
        <br>
        Provide an analytic report of 1,500 words or less that is structured as outlined below, utilizing the dataset.txt provided by Wells Fargo.</p>

        <img src="../img/socialmedialogos.jpg" height="200" width="500"><br>

        <h4 class="projecth4"> ~ Describe Your Approach and Methodology</h4>

        <h4 class="projecth4"> ~ Preparing the Data</h4>
        <p>Wells Fargo has given us 220,377 social media data. With this data, we had to obtain useful information that would be helpful in answering the 2 questions set forth from the Wells Fargo Data Competition. The language of choice for this competition was R. We uploaded the necessary data using RStudio as our choice of IDE. We have observed the type of data we are to be working with and found that we were working with both Facebook and Twitter comments and posts. The pre-process portion was to remove unnecessary data. Unnecessary data consisted of removal of spaces, specific words and non associated posts and comments from the two social media platforms. During this time, we sample roughly 10,000 observations to decrease the number of observations of 220,377 that we had to work with when organizing the data. We have orgranized the data by bank as well as relevant and non-relevant terms using sentiment analysis.</p>

        <img src="../img/FlowChart.png"><br>

        <h4 class="projecth4"> ~ Discuss the Data and its Relationship to Social Conversation Drivers</h4>

        <p>
        Investigate the social conversation drives using the data provided. After retrieving the postive and negative sentiment phrases and words, we have identified conversation drivers such as customer service, account issues. This data provided is key to providing an idea of what can be considered as a social driver for these banks.
        </p>
 
        <h4 class="projecth4"> ~ Document your Code and Reference the Analytic Process Flow-Diagram</h4>

        <pre>
          <code>
# Load data set, in my case ('df.Rda')
load("/Users/Casey/Downloads/df.Rda")
df$FullText = as.character(df$FullText)

# Grab just the texts, so you can load them in the Corpus
df.texts = as.data.frame(df[,ncol(df)])
colnames(df.texts) = 'FullText'

# Remove non-ascii characters
df.texts.clean = as.data.frame(iconv(df.texts$FullText, "latin1", 
                                     "ASCII", sub=""))
colnames(df.texts.clean) = 'FullText'

df$FullText = df.texts.clean$FullText

# To test on 10000 samples using df.10000
idx.10000 = sample(1:nrow(df),10000)
df.10000 = df[idx.10000,]

df.entire = df
df = df.10000

# Load in corpus form using the tm library
library(tm) 
docs <- Corpus(DataframeSource(as.data.frame(df[,6])))   

# Perform pre-processing
docs <- tm_map(docs, PlainTextDocument)
docs <- tm_map(docs, removePunctuation)
docs <- tm_map(docs, stripWhitespace)
docs <- tm_map(docs, removeWords,c("Name","and","for")) 
docs <- tm_map(docs, removeWords, stopwords("english"))
docs <- tm_map(docs, removeWords, stopwords(kind="SMART"))

save.image('docs.preprocessed.Rda')
load('docs.preprocessed.Rda')

# Documents containing each bank
bankA.idx = which(sapply(df$FullText,function(x) grepl("BankA",x)))
bankB.idx = which(sapply(df$FullText,function(x) grepl("BankB",x)))
bankC.idx = which(sapply(df$FullText,function(x) grepl("BankC",x)))
bankD.idx = which(sapply(df$FullText,function(x) grepl("BankD",x)))

df$BankID = vector(mode="numeric", length = nrow(df))
df$BankID[bankA.idx] = "BankA"
df$BankID[bankB.idx] = "BankB"
df$BankID[bankC.idx] = "BankC"
df$BankID[bankD.idx] = "BankD"

bankA.docs = docs[bankA.idx]
bankB.docs = docs[bankB.idx]
bankC.docs = docs[bankC.idx]
bankD.docs = docs[bankD.idx]

summary(docs)

## Repeat these processes for every bank
## Create document term matrix
dtm <- DocumentTermMatrix(docs[bankA.idx])

## Transpose this matrix
tdm <- TermDocumentMatrix(docs[bankA.idx])

## Remove sparse terms
dtm = removeSparseTerms(dtm, 0.98)

## Organize terms by frequency
findFreqTerms(dtm,50)
freq <- colSums(as.matrix(dtm))  
ord <- order(freq)   
freq[head(ord)]  
freq[tail(ord)]

wf <- data.frame(word=names(freq), freq=freq)   
head(wf)
          </code>
        </pre>

        <h4 class="projecth4"> ~ Create a List of Topics and Substance</h4>
        <br>
        <li>
          <ul>Account</ul>
        </li>
        <li>
          <ul>ATM</ul>
        </li>
        <li>
          <ul>Check</ul>
        </li>
        <li>
          <ul>Customer Service</ul>
        </li>
        <li>
          <ul>Credit</ul>
        </li>
        <li>
          <ul>Grants</ul>
        </li>
        <li>
          <ul>Management</ul>
        </li>
        <li>
          <ul>Phone Calls</ul>
        </li>
        <br>


        frequency. 
        <br>
        The results were then tested against the results as a whole.
        </p>

        <img src="../img/socialmedia.jpg" height="300" width="500"><br>

      </section>
       
      <section id="secondary">

      <img src="../img/socialmediatree.png" width="300"><br>

      <h3 class="projecth3">Narrative Insight</h3>

       <img src="../img/wordcloud.png" height="300" width="300"><br>
       <h3 class="projecth3">Word Cloud</h3>
       <pre>
          <code>
## To get a word cloud of the 100 most frequent words 
library(wordcloud)
set.seed(142)   
dark2 <- brewer.pal(6, "Dark2")   
wordcloud(names(freq), freq, max.words=25, rot.per=0.2, colors=dark2)
          </code>
        </pre>

        <img src="../img/Dendrogram.png" height="300" width="300"><br>

        <h3 class="projecth3">Dendrograph</h3>
       <pre>
          <code>
##Cluster Dendrogram
docs <- tm_map(docs, removeWords,c("Name", "and","for", "name", "this", "are","from", "just", "get", "ret_twit", "name_resp", "twit_hndl", "twit_handl:", "twit_hndl_banka","ly/")) 
docs <- tm_map(docs, removeWords, stopwords("english"))
docs <- tm_map(docs, removeWords, stopwords(kind="SMART"))

dtm <- DocumentTermMatrix(docs)
tdm <- TermDocumentMatrix(docs)
          </code>
        </pre>

        <h3 class="projecth3">K-Means Clustering</h3>
       <pre>
          <code>
#K-Means Clustering
library(fpc)
library(cluster)   
d <- dist(t(m2), method="euclidian")
kfit <- kmeans(d, 2)   
clusplot(as.matrix(d), kfit$cluster, color=T, shade=T, labels=2, lines=0)
          </code>
        </pre>

      </section>

      <footer>
        <a href="http://facebook.com/caseychadsalvador" target="_blank"><img src="img/facebook.png" alt="Facebook Logo" class="social-icon"></a>
        <a href="https://instagram.com/mrkeishii/" target="_blank"><img src="img/instagram.png" alt="Instagram Logo" class="social-icon"></a>
        <a href="http://twitter.com/mrkeishii" target="_blank"><img src="img/twitter.png" alt="Twitter Logo" class="social-icon"></a>
        <p>&copy; 2015 Casey Salvador.</p>
      </footer>

    </div> <!-- wrapper div tag -->

  </body>

</html>
